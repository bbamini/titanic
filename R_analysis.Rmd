---
title: "Titanic Kaggle"
author: "Bamini Balaji"
date: "May 28, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/bamini/Documents/Coursera/Projects/titanic")
```
<br>

### Introduction

The objective is to build a binary classification model on the Titanic training dataset and use this model to predict which individuals surivived the tragedy. 

Let's start by downloading the data sets and loading necessary packages.

```{r, warning=FALSE, results="hide", message=FALSE}
train <- read.csv("train.csv", na.strings = "", colClasses = c("Survived" = "factor", "Name" = "character",
                                                               "Pclass" = "factor"))
test <- read.csv("test.csv", na.strings = "", colClasses = c("Survived" = "factor", "Name" = "character",
                                                             "Pclass" = "factor"))

library(ggplot2)
library(dplyr)
library(cowplot)
library(stringr)
library(knitr)
library(VIM)
library(class)
library(caret)
library(MASS)
library(randomForest)
library(e1071)
```

<br>

### Exploratory Analyses


The dataset includes the following columns:

```{r, echo=FALSE}
str(train)
```

Let's observe the correlations between any numeric predictor variables:

```{r}
pairs(train[, c("Pclass", "Age", "SibSp", "Parch", "Fare")], col = train$Survived)
```



<br>

#### Socioeconomic Status

Socioeconomic status is reflected in the pclass variable. Let's look at this more carefully:

```{r, echo=FALSE}
rate <- ggplot(train, aes(as.factor(Pclass),fill = as.factor(Survived)))+
  geom_bar(position = "fill")+
  xlab("Ticket Class") + 
  ylab("% Passengers") +
  ggtitle("% Survival by Ticket Class") +
  scale_fill_discrete(name = "Survived?", labels = c("No", "Yes"))

counts <- ggplot(train, aes(as.factor(Pclass),fill = as.factor(Survived)))+
  geom_bar()+
  xlab("Ticket Class") + 
  ylab("Number of Passengers") +
  ggtitle("Survival Counts by Ticket Class") +
  scale_fill_discrete(name = "Survived?", labels = c("No", "Yes"))

plot_grid(rate, counts, ncol = 2, nrow = 1)
```

Most passengers were in the third class and of this ticket class over half the population did not survive. In contrast, the number of passengers in first class that survived exceeded the number of first class passengers who perished. Hence you were less likely to survive if you were in the lower ticket class.

<br>

#### Fare

What about the fare that the passenger paid? 

```{r, echo=FALSE}
# ggplot(data = na.omit(train[, c("Pclass", "Fare", "Survived", "Embarked")]), aes(as.factor(Pclass), Fare))+
#   geom_boxplot(aes(color = Embarked), na.rm = TRUE, outlier.shape = NA) +
#   ylim(0, 200) +
#   xlab("Ticket Class") + 
#   ggtitle("Fare vs. Ticket Class and Port of Embarkation") +
#   scale_color_discrete(name = "Embarked in", breaks = c("C", "Q", "S"), 
#                       labels = c("Cherbourg", "Queenstown", "Southampton"))

p <- ggplot(data = train, aes(as.factor(Pclass), Fare), color = as.factor(Pclass)) + 
  geom_boxplot(aes(color = as.factor(Pclass)), outlier.color = NA) +
  xlab("Ticket Class") +
  theme(legend.position = "none")
emb <- ggplot(data = na.omit(train[, c("Fare", "Embarked")]), aes(Embarked, Fare), color = Embarked) + 
  geom_boxplot(aes(color = Embarked), outlier.color = NA) +
  theme(legend.position = "none")

plot_grid(p, emb, ncol = 2, nrow = 1)

```

Clearly the fare correlates with ticket class and to some extent with port of embarkation.

```{r, echo=FALSE}
ggplot(train, aes(Fare, fill = as.factor(Survived)))+
  geom_density(alpha = 0.25, na.rm = TRUE)+
  # xlab("Ticket Class") + 
  # ylab("Total Passengers") +
  ggtitle("Fare Density Plot by Survival") +
  scale_fill_discrete(name = "Survived?", labels = c("No", "Yes"))
```

It appears that the distribution of those who survived is shifted to higher average fare compared to the distribution of those who perished. However this may be due to the previous shown correlations.

<br>

#### Age

Let's look at age distributions:

```{r, echo=FALSE}
ggplot(train, aes(Age, fill = as.factor(Survived)))+
  geom_density(alpha = 0.25, na.rm = TRUE)+
  # xlab("Ticket Class") + 
  # ylab("Total Passengers") +
  ggtitle("Age Density Plot by Survival") +
  scale_fill_discrete(name = "Survived?", labels = c("No", "Yes"))
```

This shows that your chances of survival were greater if you were under 10. Let's create a logical variable for age under 10. 


<br>

#### Family Aboard

The variables `r names(train)[7]` and `r names(train)[8]` represent how many siblings/spouses or how many parents/children were aboard respectively. Let's combine these into a single feature for number of family members. 
Did having family aboard increase one's odd of survival? 

```{r, warning=FALSE}
newtrain <- mutate(train, Famsize = SibSp + Parch)
```

```{r, echo=FALSE, warning=FALSE}
# sib <- ggplot(train, aes(SibSp, Survived))+
#   geom_jitter()+
#   xlab("Ticket Class") + 
#   ylab("Total Passengers") +
#   ggtitle("Survival Counts by # Siblings") +
#   scale_fill_discrete(name = "Survived?", labels = c("No", "Yes"))
# 
# parents <- ggplot(train, aes(Parch,Survived))+
#   geom_jitter()+
#   xlab("Ticket Class") + 
#   ylab("Total Passengers") +
#   ggtitle("Survival Counts by Parents/Children aboard") +
#   scale_fill_discrete(name = "Survived?", labels = c("No", "Yes"))
# 
# plot_grid(sib, parents, ncol = 2, nrow = 1)

ggplot(newtrain, aes(Famsize, fill = as.factor(Survived)))+
  geom_bar(position = "fill")+
  xlab("Number of Family Members Aboard") + 
  ylab("% Passengers") +
  ggtitle("% Survival by Family Size") +
  scale_fill_discrete(name = "Survived?", labels = c("No", "Yes"))
```

It appears that traveling with 1 - 3 family members improved one's odds of survival over traveling alone or traveling with a large family. So let's create a factor variable of family size with three categories 0, 1-3, and greater than or equal to 4. 

```{r}
newtrain <- mutate(newtrain, nfamily = ifelse(Famsize == 0, "none", ifelse(
  Famsize > 3, "large", "small")))
```




<br>

#### Gender

Did one gender survive more than another?

```{r, echo=FALSE}
ggplot(train, aes(Sex,fill = as.factor(Survived)))+
  geom_bar(colour = "black")+
  xlab("Ticket Class") + 
  ylab("Total Passengers") +
  ggtitle("Survival Counts by Sex") +
  scale_fill_discrete(name = "Survived?", labels = c("No", "Yes"))
```

Women were more likely to survive than men. 

<br>


#### Port of Embarkation

Did the port of embarkation matter for survival odds?

```{r, echo=FALSE}
rate <- ggplot(train, aes(as.factor(Embarked),fill = as.factor(Survived)))+
  geom_bar(position = "fill")+
  xlab("Ticket Class") + 
  ylab("% Passengers") +
  ggtitle("% Survival by Origin City") +
  scale_fill_discrete(name = "Survived?", labels = c("No", "Yes"))

counts <- ggplot(train, aes(as.factor(Embarked),fill = as.factor(Survived)))+
  geom_bar()+
  xlab("Ticket Class") + 
  ylab("Number of Passengers") +
  ggtitle("Survival Counts by Origin City") +
  scale_fill_discrete(name = "Survived?", labels = c("No", "Yes"))

plot_grid(rate, counts, ncol = 2, nrow = 1)
```

It appears that the port of embarkation did not have a significant effect on survival odds.

<br>

#### Name Analyses

```{r}
head(train$Name)
```

The Name feature is interesting as it provides an individuals title. This can be useful information. 


```{r}
newtrain <- mutate(newtrain, title = str_replace(str_extract(Name, "[a-zA-Z]+[.]"), "[.]", ""))
kable(t(summary(as.factor(newtrain$title))))
```

In addition to the more common tiles (such as Ms, Miss, Mr, Mrs, Master), there are entries such as Don, Jonkheer, Lady, Countess etc. Let's re-categorize these less popular entries as follows:

* Capt, Col, Don, Jonkheer, Major, Sir --> Mr
* Countess, Lady, Mme, Ms, Dona --> Mrs
* Mlle --> Miss

```{r, warning=FALSE, message=FALSE}
update_title <- function(old_title){
  if (is.element(old_title, c("Capt", "Col", "Don", "Jonkheer", "Major", "Sir"))) {
    new_title <- "Mr"
  } else if (old_title %in% c("Countess", "Lady", "Mme", "Ms", "Dona")) {
    new_title <- "Mrs"
  } else if (old_title == "Mlle") {
    new_title <- "Miss"
  } else if (old_title %in% c("Dr", "Master", "Miss", "Mr", "Mrs", "Ms", "Rev")) {
    new_title <- old_title
  }
  return(new_title)
}

newtitles <- sapply(newtrain$title, update_title)
newtrain$title <- as.factor(newtitles)

kable(t(summary(newtrain$title)))
```

<br>


### Missing Data

Several features have missing data. The entire training data set has `r dim(train)[1]` observations.

```{r}
aggr(train, prop = FALSE, numbers = TRUE, combined = TRUE, sortVars = TRUE)
```


For the purposes of this analysis, let's omit the Cabin feature because too much information is missing.
Let's try to impute the missing values for Age and Embarked.

<br>

#### Port of Embarkation

Let's try to deduce the missing Port of embarkation 

```{r}
subset(train, is.na(Embarked))
```

It appears that these two women were not accompanied by any family. However we do have information on their fare and ticket class. 

Let's try using k-nearest neighbors on the fare where ticket class is 1 to predict port of embarkation. Note Pclass is not included for knn because it is categorical and we shouldn't consider information from other ticket classes when these two individuals were in Pclass = 1.

```{r}
ggplot(train, aes(Pclass, Fare, color = Embarked)) + geom_jitter() + geom_hline(yintercept = 80, color = "black")
pclass1 <- filter(train, Pclass == 1)
predictors <- dplyr::select(pclass1, Fare)
missing_emb <- is.na(pclass1$Embarked)
knn(data.frame(predictors[!missing_emb,]), data.frame(predictors[missing_emb,]), pclass1$Embarked[!missing_emb], k = as.integer(sqrt(dim(pclass1)[1])))
```


We predict that the individuals likely embarked from Southampton.
Based on some [research] (https://www.encyclopedia-titanica.org/titanic-survivor/martha-evelyn-stone.html) we can see that these two passengers did in fact boarded from Southampton! 


```{r}
newtrain$Embarked[which(is.na(newtrain$Embarked))] <- "S"
```



<br>

#### Impute Age

It's hard to estimate the missing ages using a linear model because none of the continous predictors would logically correlate. 
However, the title likely correlates on average with the age. So let's impute ages as grouped averages by title. 

```{r, echo=FALSE}
ggplot(newtrain, aes(Age, fill = as.factor(title)))+
  geom_density(alpha = 0.25, na.rm = TRUE)+
  ggtitle("Age Density Plot by Title")+
  scale_fill_discrete(name = "Title", labels = levels(newtrain$title))
```


```{r}
missing_age <- is.na(newtrain$Age)
train_age <- newtrain[!missing_age, ]
average_age <- aggregate(train_age$Age, by=list(train_age$title), mean, na.rm = TRUE)

impute.mean <- function(x) replace(x, is.na(x), round(mean(x, na.rm = TRUE)))
newtrain <- newtrain %>% group_by(title) %>% mutate(Age = impute.mean(Age))
```

As stated previously, let's create the logical variable for age under 10.

```{r}
newtrain <- mutate(newtrain, Young = ifelse(Age > 10, FALSE, TRUE))
```



<br>

### Prediction Model
<br>

#### Cleaning Test Data


Let's start by creating the title column.

```{r}
newtest <- mutate(test, title = str_replace(str_extract(Name, "[a-zA-Z]+[.]"), "[.]", ""))
kable(t(summary(as.factor(newtest$title))))

newtitles <- sapply(newtest$title, update_title)
newtest$title <- as.factor(newtitles)

newtest <- mutate(newtest, Famsize = SibSp + Parch)
newtest <- mutate(newtest, nfamily = ifelse(Famsize == 0, "none", ifelse(Famsize > 3, "large", "small")))
```


Now let's check for missing information in the test data set. 

```{r}
aggr(newtest, prop = FALSE, numbers = TRUE, combined = TRUE, sortVars = TRUE)
```

We can impute missing age values using the same method.


```{r}
#Renaming columns to match the model

newage <- c()
for (i in 1:dim(newtest)[1]) {
  if (is.na(newtest$Age[i])) {
    if (newtest$title[i]== "Dr" ) {newage[i] <- 42.00}
    if (newtest$title[i]== "Master" ) {newage[i] <- 5.00}
    if (newtest$title[i]== "Miss" ) {newage[i] <- 22.00}
    if (newtest$title[i]== "Mr" ) {newage[i] <- 33.00}
    if (newtest$title[i]== "Mrs" ) {newage[i] <- 36.00}
    if (newtest$title[i]== "Rev" ) {newage[i] <- 43.00}
  } else {
    newage[i] <- newtest$Age[i]
  }
}

newtest <- mutate(newtest, Age = newage)

newtest <- mutate(newtest, Young = ifelse(Age > 10, FALSE, TRUE))
```
<br>


Now let's impute the missing Fare value in the test data set. 
As shown before, fare is dependent on Pclass and port of embarkation. 

```{r}
missingfare <- subset(newtest, is.na(Fare))

fit_fare <- lm(Fare ~ Pclass + Embarked, newtrain)
model_fare <- predict(fit_fare, missingfare)

newtest$Fare[as.numeric(rownames(missingfare))] = model_fare
```

<br>

#### Approach

The approach is to create a few models and determine which would be the best model to predict the test set.
Here are the models:

1. Logistic Regression
2. Linear Discriminant Analysis
3. Bagging with Decision Trees
4. Random Forest
5. Support Vector Machine

In order to determine the best model, let's perform cross validation using 25% of the training data set. 

```{r}
set.seed(101)
train_subset <- createDataPartition(y = newtrain$Survived, p = 0.75, list = FALSE)
drop.cols <- c('PassengerId', 'Name', 'Ticket', 'Cabin', 'Famsize')
newtrain_rev <- dplyr::select(newtrain, -one_of(drop.cols))
training <- newtrain_rev[train_subset, ]
validation <- newtrain_rev[-train_subset, ]
```

<br>

#### Prediction Models

Let's build the models and evaluate the accuracy of each model's prediction against the validation set


```{r, message=FALSE, warning=FALSE}
# Logistic Regression
glm_fit <- glm(Survived ~ Pclass + Sex + SibSp + Parch + Fare + Age + Embarked, 
               family = binomial(link='logit'), data = training)
glm_fit_simple <- glm(Survived ~ Pclass + Sex + Fare + Young + nfamily + title, 
                      family = binomial(link='logit'), data = training)

# Linear Discriminant Analysis
lda_fit <- lda(Survived ~ Pclass + Sex + Fare + Young + nfamily + title, 
               data = training)

# Bagging with Decision Trees
bag_fit <- train(Survived ~ Pclass + Sex + Fare + Young + nfamily + title, 
                 data = training, method = "treebag")

# Random Forest
rf_fit <- train(Survived ~ Pclass + Sex + Fare + Young + nfamily + title,
                data = training, method = "rf")

# Support Vector Machines
svm_fit <- svm(Survived ~ Pclass + Sex + SibSp + Parch + Fare + Age + Embarked, 
               data = training, kernel = "linear")
svm_fit_simple <- svm(Survived ~ Pclass + Sex + Fare + Young + nfamily + title,
                      data = training, kernel = "linear")

CM_glm <- confusionMatrix(validation$Survived, as.factor(round(predict(glm_fit, validation, type = "response"))))
CM_glm_simple <- confusionMatrix(validation$Survived, as.factor(round(predict(glm_fit_simple, validation, type = "response"))))
CM_lda <- confusionMatrix(validation$Survived, predict(lda_fit, validation)$class)
CM_bag <- confusionMatrix(validation$Survived, predict(bag_fit, validation))
CM_rf <- confusionMatrix(validation$Survived, predict(rf_fit, validation))
CM_svm <- confusionMatrix(validation$Survived, predict(svm_fit, validation))
CM_svm_simple <- confusionMatrix(validation$Survived, predict(svm_fit_simple, validation))

# Calculate model accuracies
sapply(list(glm = CM_glm, glm_simple = CM_glm_simple, lda = CM_lda, bagging = CM_bag, RF = CM_rf, SVM = CM_svm, SVM_simple = CM_svm_simple), 
       function(x) x$overall["Accuracy"])

```

<br>

#### Test Set Prediction

```{r}
drop.cols <- c('PassengerId', 'Name', 'Ticket', 'Cabin')
newtest_rev <- dplyr::select(newtest, -one_of(drop.cols)) 

glm_pred <- data.frame(PassengerId = newtest$PassengerId, Survived = as.factor(round(predict(glm_fit, newtest_rev, type = "response"))))
glm_sim_pred <- data.frame(PassengerId = newtest$PassengerId, Survived = as.factor(round(predict(glm_fit_simple, newtest_rev, type = "response"))))
lda_pred <- data.frame(PassengerId = newtest$PassengerId, Survived = predict(lda_fit, newtest_rev)$class)
bag_pred <- data.frame(PassengerId = newtest$PassengerId, Survived = predict(bag_fit, newtest_rev))
rf_pred <- data.frame(PassengerId = newtest$PassengerId, Survived = predict(rf_fit, newtest_rev))
svm_pred <- data.frame(PassengerId = newtest$PassengerId, Survived = predict(svm_fit, newtest_rev))
svm_sim_pred <- data.frame(PassengerId = newtest$PassengerId, Survived = predict(svm_fit_simple, newtest_rev))
```

```{r, echo=FALSE}
write.csv(glm_pred, file = "glm_pred.csv", row.names = FALSE)
write.csv(glm_sim_pred, file = "glm_sim_pred.csv", row.names = FALSE)
write.csv(lda_pred, file = "lda_pred.csv", row.names = FALSE)
write.csv(bag_pred, file = "bag_pred.csv", row.names = FALSE)
write.csv(rf_pred, file = "rf_pred.csv", row.names = FALSE)
write.csv(svm_pred, file = "svm_pred.csv", row.names = FALSE)
write.csv(svm_sim_pred, file = "svm_sim_pred.csv", row.names = FALSE)

```

